#output_dir: ./outputs

defaults:
  - _self_
  # - override hydra/hydra_logging: disabled
  # - override hydra/job_logging: disabled
  - override hydra/launcher: submitit_slurm

hydra:
  output_subdir: null
  mode: MULTIRUN
  launcher:
    max_num_timeout: 999
    gpus_per_node: 4
    tasks_per_node: ${hydra.launcher.gpus_per_node}
    cpus_per_task: 8
    mem_gb: 64
    timeout_min: 1080
    partition: long
    signal_delay_s: 120
    constraint: lovelace
    # setup:
    # [
    #   "tar -czf \"$SLURM_TMPDIR/stablewm.tgz\" -C \"$STABLEWM_HOME\" .",
    #   "tar -xzf \"$SLURM_TMPDIR/stablewm.tgz\" -C \"$SLURM_TMPDIR\"",
    #   "rm -f \"$SLURM_TMPDIR/stablewm.tgz\""
    # ]
  run:
    dir: .

wandb:
  enable: false
  project: xenoworlds
  entity: simon-lacoste-julien

dataset_name: pusht_expert_train
# cache_dir: null #${oc.env:SLURM_TMPDIR, null}
output_model_name: dinowm_reprod

trainer:
  max_epochs: 100
  strategy: ddp
  devices: auto
  accelerator: gpu
  precision: 16-mixed

batch_size: 32
num_workers: 16
train_split: 0.9
seed: 42

image_size: 224
patch_size: 16

n_steps: ${eval:'${dinowm.num_preds} + ${dinowm.history_size}'}
frameskip: 5

dinowm:
  history_size: 3
  num_preds: 1
  proprio_dim: 4
  proprio_embed_dim: 10
  action_dim: 2
  action_embed_dim: 10

predictor:
  depth: 6
  heads: 16
  mlp_dim: 2048
  dim_head: 64
  dropout: 0.1
  emb_dropout: 0.0

predictor_lr: 5e-4
proprio_encoder_lr: 5e-4
action_encoder_lr: 5e-4

dump_object: True
